<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>The Toolbox</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://malpaw.github.io/"/>
  <updated>2017-06-29T18:52:52.498Z</updated>
  <id>http://malpaw.github.io/</id>
  
  <author>
    <name>malpaw</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Test Delayed Development</title>
    <link href="http://malpaw.github.io/2016/01/31/test-delayed-development/"/>
    <id>http://malpaw.github.io/2016/01/31/test-delayed-development/</id>
    <published>2016-01-31T17:08:02.000Z</published>
    <updated>2017-06-29T18:52:52.498Z</updated>
    
    <content type="html"><![CDATA[<p>Test Driven Development is a commonly recognized term and probably the most acclaimed development practice out there. Nowadays, it is near to impossible to find a developer, architect or a project manager not entirely convinced this paradigm is worth implementing. Or is it so?</p><p>First, let me remind you what the arguments for TDD are:</p><ul><li>Having to implement tests, you will have to deeply understand what your code is supposed to do in the first place. Do not underestimate this opportunity.</li><li>It will also force you to rethink your architecture and use at least some of the trustworthy design patters, e.g. Inversion of Control, before you start coding.</li><li>You will be able to actually run and test your code without needing to integrate it with the rest of the application.</li><li>Testing edge cases will give you a picture what potential security security and performance issues should be mitigated.</li><li>Tests can be themselves the best user documentation you could ever write.</li><li>You can safely refactor your code anytime – thus you can also afford not to invest too much into its versatility until it’s really needed.</li></ul><p>I have seen many projects where teams were dedicated to implement all kinds of automated tests before the project started and then dropped this idea shortly after the development commenced. I can understand some of the reasoning behind this:</p><ul><li>Implementing tests <em>is</em> time-consuming even if it will spare even more time in the future. Thus, it is hard to “sell” the idea to some uneducated clients.</li><li>Under a tight schedule, with the upcoming deadlines, it is too easy to cut the corners and give up implementing tests (temporarily, of course).</li><li>In some cases, implementing meaningful automated tests is very difficult, e.g. for thin-client web applications without much business logic.</li><li>Implemented and then maintaining automated tests in general requires a lot of effort. Usually a lot more than implementing and maintaining the code being tested. It sounds daunting.</li><li>Therefore, it is very tempting to disable failing tests or to implement “dummy” tests instead (they always pass without detecting real problems).</li></ul><p>So, what you can do to help your teams keeping up the good quality and adhere to the best practices? Obviously, just committing to implementing test is not enough and will, in the worst case, lead to a slow-but-steady decay and eventually – dropping them all together.</p><p>I have a couple ideas on how to make this a sustainable process, to convert a chore into a habit. I hope you will implement them while working on your projects and then share, what the outcomes are.</p><ul><li>Make unit tests, integration tests and UI tests parts of your Definition of Done. Consider them integral part of your development process. Code is not finished – not <em>working</em> – until it is not covered with enough number of tests (dummy tests do not count!) Let the other team member check tests written by their colleagues.</li><li>Add the time needed to implement and maintain tests to your estimates. Adding them to the DoD will help you justifying your estimates.</li><li>Maintain the tests whenever they require it. Do not ever disable tests only because they stared to fail. Fix the code and extend the test cases instead.</li><li>Configure the automatic build environment and run all short-running tests after each commit. If some tests require more than 15 minutes to run, schedule them to a nighttime.</li><li>Create reports from automated test runs and pass them to the management and clients on a regular basis. Advertise your concern over quality, it will help you defending your case.</li><li>Educate your clients and management on every opportunity. Make <em>them</em> wanting you to deliver the tests as an inseparable part of the code you produce; implementing and maintaining the tests – a necessary part of the production process.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Test Driven Development is a commonly recognized term and probably the most acclaimed development practice out there. Nowadays, it is nea
      
    
    </summary>
    
    
      <category term="tdd" scheme="http://malpaw.github.io/tags/tdd/"/>
    
  </entry>
  
  <entry>
    <title>What Makes an Enterprise CMS?</title>
    <link href="http://malpaw.github.io/2016/01/06/what-makes-an-enterprise-cms/"/>
    <id>http://malpaw.github.io/2016/01/06/what-makes-an-enterprise-cms/</id>
    <published>2016-01-06T13:25:15.000Z</published>
    <updated>2017-06-29T18:52:52.498Z</updated>
    
    <content type="html"><![CDATA[<p>Recently I stumbled upon a website advertising an enterprise-grade CMS and Commerce suite written in node.js. I grew my interests in JavaScript after I was forced to implement a module performing the same job on both client and server side. I thought having a JavaScript backend engine would really help me not to repeat myself. Well, it was not possible then, but I was looking ever since.</p><p>I’ve been looking for a good, stable and having a rich feature set node-based CMS for several months. After the development of <a href="http://buckets.io/" target="_blank" rel="noopener">bucket.io</a> has stalled and then been put on hold, I lost hope for finally seeing some mature solution, even a simple one as Buckets seemed to be. It’s no wonder I got excited after seeing <a href="http://nodejsenterprise.com/" target="_blank" rel="noopener">NodeJS Enterprise</a> landing page.</p><p>The website offers CMS and Commerce modules along with Docker manager tool. The CMS tool is in beta state, the rest is being developed, but nevertheless it looks promising. I focused on the CMS only due to the live demo available for previewing. Full of hopes I opened it and found following set of features:</p><ul><li>Simple user manager;</li><li>Page editor with tree website structure view;</li><li>Image library;</li><li>Public assets manager;</li><li>Online template and widget editor;</li><li>Form editor.</li></ul><p>Even if it is not strictly a basic set, still it is not very impressive and definitely I wolud not use word “enterprise” to describe it yet. So what makes an enterprise CMS, then?</p><h2><span id="what-companies-need">What companies need</span></h2><p>The most common setup for companies that are no longer family businesses is having multiple parties involved in producing content. It does not only mean individuals, i.e. multiple editors with different sets of access rights, but also whole company divisions with multiple editors working for each of them. It implies at least the following:  </p><ul><li>Content should have history. Each change should be tracked, every version should be restorable.</li><li>The content should be searchable, thus tight integration with a scalable full-text search engine is a must-have.</li><li>The platform should be able to host multiple sites, possibly utilizing different sets of templates and layouts but often sharing the same content.</li><li>The editors’ responsibilities might vary across the organization and its divisions. The platform should allow for defining multiple roles and workflows. Someone enters content, someone translates, finally someone accepts it.</li><li>Enterprise sites are multilingual. Organizations tend to commission translating content to third parties. Thus exporting and importing content is a desired feature.</li><li>With large amount of content the ability to define page publication date and time is crucial. </li><li>Large organizations use multiple systems. The CMS platform needs to be extensible and to exchange information with these systems. For example, integration with corporate Digital Asset Management solution enables the organization to implement asset usage policies.</li></ul><p>and finally</p><ul><li>The corporate CMS solution has to allow different hosting and deployment scenarios to meet organization’s security policies.</li><li>It should allow deploying a web farm, loadbalancing.</li><li>It should help promoting content from staging environments to production.</li><li>It should separate Content Management from Content Delivery environments.</li></ul><p><a href="http://nodejsenterprise.com/" target="_blank" rel="noopener">NodeJS Enterprise</a> is not there yet. It is, however, a very promising project. I will surely watch how it grows and becomes mature.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Recently I stumbled upon a website advertising an enterprise-grade CMS and Commerce suite written in node.js. I grew my interests in Java
      
    
    </summary>
    
    
      <category term="cms" scheme="http://malpaw.github.io/tags/cms/"/>
    
      <category term="node.js" scheme="http://malpaw.github.io/tags/node-js/"/>
    
  </entry>
  
  <entry>
    <title>Simple Vagrant Box for Elasticsearch</title>
    <link href="http://malpaw.github.io/2015/12/28/simple-vagrantbbox-for-elasticsearch/"/>
    <id>http://malpaw.github.io/2015/12/28/simple-vagrantbbox-for-elasticsearch/</id>
    <published>2015-12-28T15:37:40.000Z</published>
    <updated>2017-06-29T18:52:52.498Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.elastic.co/products/elasticsearch" target="_blank" rel="noopener">Elasticsearch</a> is a search server written in Java, providing an advanced JSON interface. It is scalable, distributed and <a href="https://github.com/elastic/elasticsearch" target="_blank" rel="noopener">open source</a>.<br>There are many similar products on the market, most noticeably <a href="http://lucene.apache.org/solr/" target="_blank" rel="noopener">Solr</a> – its greatest competitor. Almost all of them, including Elasticsearch, utilize Apache Lucene indexing engine behind the scene. The difference is in the front-end API layer, technology used and, of course, the architectural choices made by their authors.</p><h2><span id="why-elasticsearch">Why Elasticsearch?</span></h2><p>My first contact with Elasticsearch was when a client – a large international company running their website on EPiServer – requested replacing their existing search solution. The first and obvious choice for me was <a href="http://find.episerver.com/" target="_blank" rel="noopener">EPiServer Find</a>, a search engine offered by EpiServer as both SaaS and On Premise. After some research and analysis, however, the client chose to host the search service themselves, build a fully customized page indexer and a C# client library. The final choice was between Elasticsearch and Solr. </p><p>Personally, I find Elasticsearch more appealing than Solr for its simple installation and configuration, self-containment (self-hosintg), distributed architecture and cluster capabilities. Even though it is a Java-based software, and maybe because of that, it is equally easy to set up on both Windows and Linux hosts. </p><p>Being a search server means it is not intended as a primary data storage for an application, even if I have seen examples of such an idea implemented in an enterprise-grade websites. Keeping all the raw data in some primary data storage (a CMS, relational database etc.) and providing a full re-index functionality gives an additional perk: an ability to upgrade and reconfigure the search engine even in a production environment, under the heavy load. For developers, the same approach makes their search servers dispensable, letting them avoid cluttering their harddrives with loads of test data.</p><h2><span id="virtualization">Virtualization</span></h2><p>Even though Elasticsearch is a self-hosted solution and does not require much prerequisites (in fact, it requires only JRE installed), I’ve chosen to install it on a virtual machine. The main reason was to get an environment I could use for both work and personal projects without the need to install and configure it multiple times. I was also interested in experimenting with its cluster functions.</p><p>I decided to use <a href="https://github.com/mitchellh/vagrant" target="_blank" rel="noopener">Vagrant</a> – a set of tools built in Ruby, a great helper for building and distributing virtualized environments. It uses one of the three hypervisors behind the scenes: VirtualBox (default), VMware and Hyper-V. It allows me to automate the environment creation process by providing a set of so-called “base boxes” – usually clean Linux images – and running configuration tools or scripts on them – a process called provisioning.</p><p>First, I tried to use the Hyper-V provider as Hyper-V was already installed on my machine. But due to the limited number of Hyper-V base boxes available, I decided to switch over to <a href="">VirtualBox</a>. I think it was smart choice considering the VirtualBox being available on Windows, Mac and Linux. Thus, now I can share my environments with front-end developers working on Macs.</p><p>Vagrant supports multiple provisioners, including <a href="https://docs.vagrantup.com/v2/provisioning/chef_solo.html" target="_blank" rel="noopener">Chef Solo</a>, <a href="https://docs.vagrantup.com/v2/provisioning/puppet_apply.html" target="_blank" rel="noopener">Puppet</a> and of course <a href="https://docs.vagrantup.com/v2/provisioning/shell.html" target="_blank" rel="noopener">shell</a> commands. For the sake of simplicity, I chose shell scripts. </p><p>The repository with my Elasticsearch server can be found here: <a href="https://github.com/malpaw/vagrant-elasticsearch" target="_blank" rel="noopener">https://github.com/malpaw/vagrant-elasticsearch</a>. After downloading it just requires invoking<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant up</span><br></pre></td></tr></table></figure></p><p>and it is ready.</p><h2><span id="what-it-is-not">What it is not</span></h2><p>The environment I created has some severe limitations. First of all it is not intended for production use – it is not secured in any way and is not configured to work in distributed scenarios. Also, it cannot handle large amounts of data very well with its limited memory and storage settings; instead of increasing the limits I would rather suggest building a cluster instead.</p><p>I am aware there are many better Vagrant Elasticsearch projects available on Github. This was, however, my first effort of making Elasticsearch available locally and it went surprisingly well. Being a “disposable” environment (i.e. being only a secondary data storage), such a VM can be easily replaced by its more advanced version in the future. For now it fits nicely into my workflow and I am happy I can spawn another development search engine by simply typing “vagrant up”.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://www.elastic.co/products/elasticsearch&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Elasticsearch&lt;/a&gt; is a search server written in Ja
      
    
    </summary>
    
    
      <category term="vagrant" scheme="http://malpaw.github.io/tags/vagrant/"/>
    
      <category term="virtualbox" scheme="http://malpaw.github.io/tags/virtualbox/"/>
    
      <category term="elasticsearch" scheme="http://malpaw.github.io/tags/elasticsearch/"/>
    
      <category term="linux" scheme="http://malpaw.github.io/tags/linux/"/>
    
      <category term="opensource" scheme="http://malpaw.github.io/tags/opensource/"/>
    
  </entry>
  
</feed>
